import cv2
import numpy as np
import controllers.handDetectionModule as htm
import math
from ctypes import cast, POINTER
from comtypes import CLSCTX_ALL # type: ignore
import comtypes # type: ignore
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume # type: ignore
import streamlit as st

def AdjustVolumeView():
    st.markdown(
        """
        <style>
        .adjust-volume-container {
            text-align: center;
            background-color: #f5f5dc;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }
        .adjust-volume-container h3 {
            color: #daa520;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    st.markdown(
        """
        <div class="adjust-volume-container">
            <h3>üì∏ ƒêi·ªÅu ch·ªânh √¢m l∆∞·ª£ng b·∫±ng c·ª≠ ch·ªâ</h3>
            <p style="color: #daa520;">S·ª≠ d·ª•ng c·ª≠ ch·ªâ tay ƒë·ªÉ ƒëi·ªÅu ch·ªânh √¢m l∆∞·ª£ng.</p>
        </div>
        """,
        unsafe_allow_html=True
    )

    # Page title
    st.markdown("# ƒêi·ªÅu khi·ªÉn volume b·∫±ng c·ª≠ ch·ªâ")
    st.markdown("### H∆∞·ªõng d·∫´n: S·ª≠ d·ª•ng ng√≥n c√°i v√† ng√≥n tr·ªè ƒë·ªÉ ƒëi·ªÅu ch·ªânh √¢m l∆∞·ª£ng")
    
    # Kh·ªüi t·∫°o c√°c bi·∫øn tr·∫°ng th√°i trong session_state
    if 'volume_stop' not in st.session_state:
        st.session_state.volume_stop = True  # Ban ƒë·∫ßu camera t·∫Øt
    
    if 'volume_started' not in st.session_state:
        st.session_state.volume_started = False
    
    # T·∫°o layout cho c√°c n√∫t ƒëi·ªÅu khi·ªÉn
    col1, col2 = st.columns(2)
    
    # N√∫t b·∫≠t/t·∫Øt camera
    with col1:
        if st.session_state.volume_stop:
            if st.button("B·∫≠t Camera", key="volume_start_btn", type="primary"):
                st.session_state.volume_stop = False
                st.session_state.volume_started = True
                st.rerun()
        else:
            if st.button("D·ª´ng Camera", key="volume_stop_btn", type="secondary"):
                st.session_state.volume_stop = True
                st.rerun()
    
    # Kh·ªüi t·∫°o khung h√¨nh ·∫£nh
    FRAME_WINDOW = st.image([])
    
    # N·∫øu camera ch∆∞a ƒë∆∞·ª£c b·∫≠t, hi·ªÉn th·ªã h∆∞·ªõng d·∫´n
    if not st.session_state.volume_started:
        st.info("Nh·∫•n n√∫t 'B·∫≠t Camera' ƒë·ªÉ b·∫Øt ƒë·∫ßu s·ª≠ d·ª•ng t√≠nh nƒÉng ƒëi·ªÅu ch·ªânh √¢m l∆∞·ª£ng.")
        return
    
    # N·∫øu camera ƒë√£ b·ªã d·ª´ng, kh√¥ng ti·∫øp t·ª•c x·ª≠ l√Ω
    if st.session_state.volume_stop:
        return
        
    # Initialize COM library before accessing audio devices
    try:
        comtypes.CoInitialize()
        
        # access system's volume control
        devices = AudioUtilities.GetSpeakers()
        interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
        volume = cast(interface, POINTER(IAudioEndpointVolume))
        # volume.GetMute()
        # volume.GetMasterVolumeLevel()
        volRange = volume.GetVolumeRange()
        volMin = volRange[0]
        volMax = volRange[1]
    except Exception as e:
        st.error(f"L·ªói khi truy c·∫≠p √¢m thanh h·ªá th·ªëng: {str(e)}")
        st.session_state.volume_stop = True
        st.session_state.volume_started = False
        return
    
    # Hi·ªÉn th·ªã th√¥ng b√°o ƒëang k·∫øt n·ªëi
    camera_placeholder = st.empty()
    camera_placeholder.info("ƒêang k·∫øt n·ªëi v·ªõi camera...")
    
    # M·ªü camera
    try:
        video = cv2.VideoCapture(0, cv2.CAP_DSHOW)
        
        # Ki·ªÉm tra xem camera c√≥ m·ªü th√†nh c√¥ng kh√¥ng
        if not video.isOpened():
            st.error("Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi camera. Vui l√≤ng ki·ªÉm tra l·∫°i thi·∫øt b·ªã camera c·ªßa b·∫°n.")
            comtypes.CoUninitialize()
            st.session_state.volume_stop = True
            st.session_state.volume_started = False
            return
        
        # X√≥a th√¥ng b√°o ƒëang k·∫øt n·ªëi
        camera_placeholder.empty()
    except Exception as e:
        st.error(f"L·ªói khi m·ªü camera: {str(e)}")
        comtypes.CoUninitialize()
        st.session_state.volume_stop = True
        st.session_state.volume_started = False
        return
        
    # Kh·ªüi t·∫°o ƒë·ªëi t∆∞·ª£ng ph√°t hi·ªán b√†n tay
    detect = htm.handDetector()
    
    # setting the captured video's dimensions if needed
    # wCam, hCam = 1920, 1080
    # video.set(3, wCam)
    # video.set(4, hCam)

    detect = htm.handDetector()  # make an object for hand detection module

    while not st.session_state.volume_stop:
        # Capture frame-by-frame
        check, frame = video.read()  # check & capture the frame
        
        # If frame is read correctly check is True
        if not check:
            st.error("Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ camera. ƒêang th·ª≠ l·∫°i...")
            continue
            
        try:
            # flip the frame for a mirror image like o/p
            frame = cv2.flip(frame, 1)
            # get landmarks & store in a list
            LmarkList = detect.findPosition(frame, draw=False)
        except Exception as e:
            st.error(f"L·ªói x·ª≠ l√Ω h√¨nh ·∫£nh: {str(e)}")
            continue
        if len(LmarkList) != 0:
            print(LmarkList[4], LmarkList[8])

            # coordinates for landmarks of Thumb & Index fingers
            x1, y1 = LmarkList[4][1], LmarkList[4][2]
            x2, y2 = LmarkList[8][1], LmarkList[8][2]

            cv2.circle(frame, (x1, y1), 15, (0, 255, 0),
                        cv2.FILLED)  # draw circle @ thumb tip
            cv2.circle(frame, (x2, y2), 15, (0, 255, 0),
                        cv2.FILLED)  # draw circle @ index tip
            cv2.line(frame, (x1, y1), (x2, y2), (7, 0, 212), 3, 5)

            # midpt. for thumb-index joining line
            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2

            # draw circle @ midpt. of the thumb-index joing line
            cv2.circle(frame, (cx, cy), 15, (255, 255, 255), cv2.FILLED)

            # joining line length
            length = math.hypot(x2 - x1, y2 - y1)

            # setting the volume
            # hand range : 50 to 200
            # volume range : -65 to 0
            vol = np.interp(length, [50, 300], [volMin, volMax])
            print(int(length), vol)
            volume.SetMasterVolumeLevel(vol, None)

            # changing colors for respective lengths of joining line
            if length <= 50:
                cv2.circle(frame, (cx, cy), 15, (237, 250, 0),
                            cv2.FILLED)  # cyan circle

            elif length >= 200:
                cv2.circle(frame, (cx, cy), 15, (250, 0, 0),
                            cv2.FILLED)  # blue circle

        # Add instructions text to the frame
        cv2.putText(frame, "Dieu chinh volume", (25, 450), cv2.FONT_HERSHEY_SIMPLEX,
                    0.7, (255, 255, 0), 2)
                    
        # Update the Streamlit UI with the processed frame
        FRAME_WINDOW.image(frame, channels='BGR')
        
        # Check if we should stop (controlled by the button outside the loop)
        if st.session_state.volume_stop:
            break
            
    # Clean up resources
    video.release()
    if 'cv2' in globals():
        cv2.destroyAllWindows()
    
    # Show a message when camera is stopped
    if not st.session_state.volume_stop:
        st.session_state.volume_stop = True
        st.success("Camera ƒë√£ d·ª´ng ho·∫°t ƒë·ªông.")
    
    # Th√™m n√∫t ƒë·ªÉ b·∫≠t l·∫°i camera
    if st.button("B·∫≠t l·∫°i camera", key="volume_restart_btn"):
        st.session_state.volume_stop = False
        st.session_state.volume_started = True
        st.rerun()
        
    # Uninitialize COM library when done
    comtypes.CoUninitialize()
