import streamlit as st
import cv2
import numpy as np
from controllers.fruit_recognition import load_model, recognize_fruit
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration # type: ignore

RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
)

class FruitRecognitionProcessor(VideoProcessorBase):
    def __init__(self, net):
        self.net = net

    def recv(self, frame):
        # Convert frame to OpenCV format
        img = frame.to_ndarray(format="bgr24")

        # Nh·∫≠n di·ªán tr√°i c√¢y
        img = recognize_fruit(img, self.net)

        # Tr·∫£ l·∫°i khung h√¨nh ƒë√£ x·ª≠ l√Ω
        return frame.from_ndarray(img, format="bgr24")

def FruitRecognitionView():
    st.markdown(
        """
        <style>
        .fruit-recognition-container {
            text-align: center;
            background-color: #fff8dc;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }
        .fruit-recognition-container h3 {
            color: #ff4500;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    st.markdown(
        """
        <div class="fruit-recognition-container">
            <h3>üì∑ Nh·∫≠n d·∫°ng tr√°i c√¢y</h3>
            <p>Ch·ªçn ch·∫ø ƒë·ªô ƒë·ªÉ nh·∫≠n di·ªán tr√°i c√¢y t·ª´ webcam ho·∫∑c t·∫£i l√™n ·∫£nh.</p>
        </div>
        """,
        unsafe_allow_html=True
    )

    # Load m√¥ h√¨nh YOLOv8n
    @st.cache_resource
    def _load_model():
        return load_model()

    net = _load_model()

    # Tabs cho Livecam v√† Upload ·∫£nh
    tab1, tab2 = st.tabs(["üìπ Livecam", "üì§ T·∫£i ·∫£nh l√™n"])

    with tab1:
        st.write("S·ª≠ d·ª•ng webcam ƒë·ªÉ nh·∫≠n di·ªán tr√°i c√¢y theo th·ªùi gian th·ª±c.")
        
        # S·ª≠ d·ª•ng streamlit-webrtc ƒë·ªÉ stream video
        webrtc_ctx = webrtc_streamer(
            key="fruit-recognition",
            rtc_configuration=RTC_CONFIGURATION,
            video_processor_factory=lambda: FruitRecognitionProcessor(net),
            media_stream_constraints={"video": {"width": {"ideal": 640}, "height": {"ideal": 480}, "frameRate": {"ideal": 20}}, "audio": False},
        )

        if webrtc_ctx.state.playing:
            st.success("Webcam ƒëang ho·∫°t ƒë·ªông. Vui l√≤ng ƒë·∫£m b·∫£o √°nh s√°ng t·ªët ƒë·ªÉ nh·∫≠n di·ªán ch√≠nh x√°c.")
        else:
            st.warning("Vui l√≤ng b·∫≠t webcam b·∫±ng c√°ch nh·∫•n n√∫t Play.")

    with tab2:
        st.write("T·∫£i l√™n ·∫£nh ƒë·ªÉ nh·∫≠n di·ªán tr√°i c√¢y.")
        uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh", type=["jpg", "jpeg", "png"])

        if uploaded_file is not None:
            # ƒê·ªçc ·∫£nh t·ª´ file
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

            if image is None:
                st.error("Kh√¥ng th·ªÉ ƒë·ªçc file ·∫£nh. Vui l√≤ng th·ª≠ file kh√°c.")
                return

            # Nh·∫≠n di·ªán tr√°i c√¢y
            result = recognize_fruit(image, net)

            # Hi·ªÉn th·ªã ·∫£nh k·∫øt qu·∫£
            st.markdown("#### ·∫¢nh k·∫øt qu·∫£")
            result_rgb = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)
            st.image(result_rgb, caption="K·∫øt qu·∫£ nh·∫≠n di·ªán tr√°i c√¢y")